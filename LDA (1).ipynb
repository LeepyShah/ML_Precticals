{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6340f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 34. Apply Linear Discriminant Analysis (LDA) to the Iris dataset to reduce its dimensionality from 4 to 2 \n",
    "# dimensions. You will visualize the LDA-reduced dataset in a 2D scatter plot using Matplotlib.\n",
    "# instructions:\n",
    "# Load the Iris dataset \n",
    "# Briefly explore the dataset to understand its structure. Print the shape of the dataset and the first few \n",
    "# rows to get an overview of the features and target variable. \n",
    "# Initialize the PCA object to reduce the dataset to 2 dimensions.\n",
    "# Fit the LDA model to the Iris dataset and transform the dataset \n",
    "# Use Matplotlib to create a scatter plot of the LDA-reduced dataset.\n",
    "# Color the points based on their respective species (Setosa, Versicolor, Virginica) to visualize how well the \n",
    "# LDA has separated the different classes.\n",
    "# Add appropriate titles and labels to the axes of the plot.\n",
    "# Include a legend to indicate which colors correspond to which species.\n",
    "\n",
    "# 66. 68. 69.\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# Load Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Explore dataset\n",
    "print(\"Shape:\", X.shape)\n",
    "print(\"First 5 rows:\\n\", pd.DataFrame(X, columns=iris.feature_names).head())\n",
    "\n",
    "# Apply LDA to reduce to 2 dimensions\n",
    "lda = LinearDiscriminantAnalysis(n_components=2)\n",
    "X_lda = lda.fit_transform(X, y)\n",
    "\n",
    "plt.scatter(X_lda[:, 0], X_lda[:, 1], c=y)\n",
    "\n",
    "plt.title(\"LDA of Iris Dataset (2 Components)\")\n",
    "plt.xlabel(\"LD1\")\n",
    "plt.ylabel(\"LD2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c837c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 35. Apply Linear Discriminant Analysis (LDA) to the Wine dataset to reduce its dimensionality and classify the \n",
    "# types of wine based on their chemical properties. You will visualize the LDA-reduced dataset in a 2D \n",
    "# scatter plot and evaluate the classification performance.\n",
    "# Dataset: You will use the Wine dataset, which consists of 178 samples of wine, each described by 13 \n",
    "# features representing different chemical properties. The target variable indicates the type of wine, which \n",
    "# can take on one of three classes (1, 2, or 3).\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "X, y = load_wine(return_X_y=True)\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# Train LDA and reduce to 2 components\n",
    "lda = LinearDiscriminantAnalysis(n_components=2)\n",
    "X_train_lda = lda.fit_transform(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = lda.predict(X_test)\n",
    "\n",
    "# Classification performance\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "plt.scatter(X_train_lda[:, 0], X_train_lda[:, 1], c=y_train)\n",
    "\n",
    "plt.title(\"LDA of Wine Dataset (2 Components)\")\n",
    "plt.xlabel(\"LD1\")\n",
    "plt.ylabel(\"LD2\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937e3ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 36. apply Linear Discriminant Analysis (LDA) to the Iris dataset using the Scikit-learn library. You will \n",
    "# preprocess the data using label encoding, perform LDA to reduce the dimensionality of the dataset, and \n",
    "# visualize the results in a 2D scatter plot.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# Load dataset\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "# Encode labels (optional here since y is already numeric)\n",
    "y_encoded = LabelEncoder().fit_transform(y)\n",
    "\n",
    "# Apply LDA\n",
    "X_lda = LinearDiscriminantAnalysis(n_components=2).fit_transform(X, y_encoded)\n",
    "\n",
    "# Plot 2D LDA result\n",
    "plt.scatter(X_lda[:, 0], X_lda[:, 1], c=y_encoded)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a916036c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 38. Dataset: You will use the Iris dataset, which consists of 150 samples of iris flowers, each described by 4 \n",
    "# features (sepal length, sepal width, petal length, and petal width). The target variable indicates the \n",
    "# species of the iris flower (Setosa, Versicolor, or Virginica). apply both Linear Discriminant Analysis (LDA) \n",
    "# and Principal Component Analysis (PCA) to the Iris dataset. You will reduce the dimensionality of the \n",
    "# dataset using both techniques and visualize the results in 2D scatter plots. You will then compare the \n",
    "# effectiveness of LDA and PCA in terms of class separability.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# Load dataset\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "# PCA reduction to 2D\n",
    "X_pca = PCA(n_components=2).fit_transform(X)\n",
    "\n",
    "# LDA reduction to 2D\n",
    "X_lda = LinearDiscriminantAnalysis(n_components=2).fit_transform(X, y)\n",
    "\n",
    "# Plot PCA and LDA side by side\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "# PCA plot\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(X_pca[:,0], X_pca[:,1], c=y)\n",
    "plt.title(\"PCA (2D)\")\n",
    "\n",
    "# LDA plot\n",
    "plt.subplot(1,2,2)\n",
    "plt.scatter(X_lda[:,0], X_lda[:,1], c=y)\n",
    "plt.title(\"LDA (2D)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a193c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 67. Use breast cancer from sklearn.datasets to load the cancer dataset. initialize the LDA object with \n",
    "# one component to reduce the dataset to 1D. use matplotlib to plot the LDA-reduced dataset.\n",
    "\n",
    "# 37.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "\n",
    "X_lda = LinearDiscriminantAnalysis(n_components=1).fit_transform(X, y)\n",
    "\n",
    "plt.scatter(X_lda, [0]*len(X_lda), c=y)\n",
    "plt.yticks([])\n",
    "plt.xlabel(\"LD1\")\n",
    "plt.title(\"LDA (1D) - Breast Cancer Dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e59026",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
